{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# How to build a simple Chatbot with stored memory using LangChain\n",
    "* Simple Chatbot LLM App.\n",
    "    * Will be able to have a conversation.\n",
    "    * Will remember previous interactions: will have memory.\n",
    "    * Will be able to store memory in a json file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c88f7",
   "metadata": {},
   "source": [
    "A chatbot app is a software application designed to simulate conversation with human users. It uses artificial intelligence (AI) to understand what someone is saying and to respond with appropriate answers. These apps can be used for various purposes like customer support, providing information, or entertainment. Essentially, it's like texting with a program that can answer questions and help with tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Concepts included\n",
    "* Chat Model vs. LLM Model:\n",
    "    *  Chat Model is based around messages.\n",
    "    *  LLM Model is based around raw text.\n",
    "* Chat History: allows Chat Model to remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584e1f0-5e9e-4e45-850c-c606234b6ee2",
   "metadata": {},
   "source": [
    "## Trick to avoid the nasty deprecation warnings from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4224a-d719-46fd-b261-dd913b17ec86",
   "metadata": {},
   "source": [
    "In this exercise we will use the LangChain legacy chain LLMChain. It works well, but LangChain displays a nasty deprecation warning. To avoid it, we will enter the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddbcf93-0b58-4506-af83-2fa2203c711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8626f160-fcd3-41ca-a5ab-3e98f11595a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed6d60-5cbd-43e4-9a69-ed71d82a2a9b",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bdc4c-484d-4ec0-89b6-5f1e979610ce",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatbot = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Human Message: the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"My favorite color is saffron.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Call the ChatModel (the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's a beautiful color choice! Saffron is a vibrant and warm hue that can bring a pop of color to any room or outfit. What do you love most about saffron?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 15, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5baac5ed-440e-47b7-878f-908332117797-0', usage_metadata={'input_tokens': 15, 'output_tokens': 40, 'total_tokens': 55, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messagesToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Check if the Chatbot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I do not have the ability to know your personal preferences or favorite color.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 13, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c4ea63d4-557c-4945-b428-7be72286402c-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* As you can see, our Chatbot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Let's add memory to our Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6062df1-33ce-436e-b5b2-cea78ae7b860",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735752cc-ecb5-4942-9ed0-b3213f5768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542bbf66-bc77-4488-8487-b55cdb8bc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e8431b-5290-4f7f-9566-a90deb060bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72392539-0f20-456b-b32d-d367b48245f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chatbot,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e40af4-1539-497d-afbf-ed38fed90838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'HII!',\n",
       " 'messages': [],\n",
       " 'text': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"HII!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b79cc08-49dd-4746-ab68-9d8ec992abb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'my name is Vikas Jangid',\n",
       " 'messages': [HumanMessage(content='HII!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Nice to meet you, Vikas Jangid! How can I help you today?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"my name is Vikas Jangid\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e69c4f-b5ed-4c68-9a2a-67a19867f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'what is my last name?',\n",
       " 'messages': [HumanMessage(content='HII!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='my name is Vikas Jangid', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Vikas Jangid! How can I help you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Your last name is Jangid.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is my last name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44245124-ef39-4269-a099-21c9c31c08bb",
   "metadata": {},
   "source": [
    "* Check the file messages.json in the root directory.\n",
    "* This is just a simple example, in the real world you probably will not save your memory in a json file. \n",
    "* And remember: the context window is limited and it affects to the cost of using chatGPT API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9faf6-2772-4ef5-8241-d1e00c761ca4",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-simple-chatbot.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-simple-chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c44ba3a6-ff9c-49c5-b5a0-23f2ff7b367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
